[important] 这个是全局prmopt，装载我的思路，一旦有修改，都必须同步整理这个文件，使用markdown语法

# MeowTalk SDK 设计思路

## 代码结构
### 核心文件
1. `types.go`
   - 定义所有共用的数据结构
   - AudioFeature: 声音特征结构（时域和频域特征）
   - AudioSample: 音频样本（文件路径、情感类型、特征）
   - EmotionStatistics: 情感统计信息（样本统计和分布）
   - SampleLibrary: 样本库（样本存储和管理）
   - SampleProcessor: 样本处理器（音频处理参数）

2. `sound_identify.go`
   - 实现声音特征提取算法
   - AudioData: 原始音频数据
   - FeatureExtractor: 特征提取器
   - 分帧处理和特征计算

3. `recording.go`
   - 音频文件加载和预处理
   - FFT和频谱分析
   - 特征提取实现
   - 样本处理流程

4. `sample_library.go`
   - 样本库核心功能
   - 特征匹配算法
   - 统计信息维护
   - 文件持久化

## 特征提取实现
### 时域特征
1. 过零率 (Zero-Crossing Rate)
   - 信号穿过零点的频率
   - 反映音频的频率特性

2. 能量 (Energy)
   - 信号的平方和
   - 反映音量大小

3. 均方根值 (Root Mean Square)
   - 能量的平方根
   - 反映有效振幅

4. 持续时间 (Duration)
   - 音频长度
   - 基于采样率计算

### 频域特征
1. 音高 (Pitch)
   - 基于基频估计
   - 使用自相关法

2. 频谱特征
   - 峰值频率：能量最大的频率分量
   - 频谱质心：频谱的"重心"
   - 频谱衰减点：85%能量点
   - 基频：使用自相关法估计

### 预处理步骤
1. 去直流分量
   - 消除信号偏置
   - 计算并减去平均值

2. 窗口处理
   - 使用汉明窗
   - 减少频谱泄漏

3. 分帧处理
   - 25ms帧长
   - 用于局部特征计算

## 样本库实现
### 数据组织
1. 样本存储
   - 按情感类型分类
   - 保存完整特征向量
   - 维护文件路径信息

2. 统计信息
   - 样本数量统计
   - 特征均值和标准差
   - 动态更新机制

### 特征匹配
1. 欧氏距离
   - 计算特征空间距离
   - 找出最相似样本

2. 马氏距离
   - 考虑特征分布
   - 标准化处理

3. 评分机制
   - 距离加权组合
   - 归一化处理
   - 置信度计算

## 算法实现
### 1. 特征提取流程
1. 音频预处理
   ```
   1. 读取音频数据
   2. 去直流分量: x[n] = x[n] - mean(x)
   3. 分帧: 25ms帧长, 10ms步长
   4. 加窗: w[n] = 0.54 - 0.46 * cos(2πn/(N-1)) // 汉明窗
   ```

2. 时域特征计算
   ```
   1. 过零率 (ZCR):
      zcr = (1/N) * Σ |sign(x[n]) - sign(x[n-1])|/2
   
   2. 短时能量 (Energy):
      energy = Σ x[n]^2
   
   3. 均方根值 (RMS):
      rms = sqrt((1/N) * Σ x[n]^2)
   ```

3. 频域特征计算
   ```
   1. FFT变换:
      X[k] = Σ x[n] * e^(-j2πnk/N)
   
   2. 功率谱:
      P[k] = |X[k]|^2
   
   3. 频谱质心:
      centroid = Σ (k * P[k]) / Σ P[k]
   
   4. 频谱衰减点:
      rolloff = k where Σ(P[0:k]) = 0.85 * Σ(P)
   
   5. 基频估计 (使用自相关法):
      R[k] = Σ x[n] * x[n+k]
      F0 = fs / argmax(R[k])
   ```

### 2. 特征匹配算法
1. 欧氏距离计算
   ```
   d_euclidean = sqrt(Σ (x_i - y_i)^2)
   ```

2. 马氏距离计算
   ```
   1. 标准化特征:
      z = (x - μ) / σ
   
   2. 计算距离:
      d_mahalanobis = sqrt((x - μ)^T * Σ^-1 * (x - μ))
      其中:
      - x 是待测特征向量
      - μ 是样本均值向量
      - Σ 是协方差矩阵
   ```

3. 综合评分
   ```
   1. 计算每个情感类别的得分:
      score = w1 * (1 / d_euclidean) + w2 * (1 / d_mahalanobis)
      其中:
      w1 = 0.4 (欧氏距离权重)
      w2 = 0.6 (马氏距离权重)
   
   2. 归一化得分:
      normalized_score = score / Σ scores
   
   3. 置信度计算:
      confidence = max(normalized_scores)
      if confidence < threshold:
          return "unknown"
   ```

### 3. 样本库更新策略
1. 懒加载更新
   ```
   1. 添加新样本时:
      - 将样本添加到对应情感类别
      - 设置 NeedUpdate = true
   
   2. 获取统计信息时:
      if NeedUpdate:
         重新计算统计信息
         NeedUpdate = false
      return Statistics
   ```

2. 增量更新
   ```
   1. 更新均值:
      μ_new = (n * μ_old + x) / (n + 1)
   
   2. 更新标准差:
      σ_new = sqrt(((n-1) * σ_old^2 + (x - μ_new)^2) / n)
   ```

## 整体架构

### 输入层
- 从Flutter接收音频流数据
- 支持WAV格式音频文件
- 音频预处理和降噪

### 特征提取层
提取以下关键声音特征：
1. 时域特征（基于分帧处理）
   - 过零率 (Zero-Crossing Rate) - 每帧计算后取平均值
   - 能量 (Energy) - 每帧计算后取平均值
   - 均方根值 (Root Mean Square)
   - 持续时间 (Duration)

2. 频域特征（基于全局信号）
   - 音高 (Pitch)
   - 峰值频率 (Peak Frequency)
   - 频谱质心 (Spectral Centroid)
   - 频谱衰减点 (Spectral Rolloff)
   - 基频 (Fundamental Frequency)

### 音频分帧处理
- 帧长：25ms
- 用于计算时域特征
- 可提高特征提取的时间分辨率
- 有助于捕捉声音的局部变化

### 情感识别层
- 基于样本库的模式匹配
- 使用欧氏距离和马氏距离进行特征比对
- 输出最匹配的情感类型和置信度

## 核心组件

### AudioData
- 存储原始音频样本
- 记录采样率信息

### FeatureExtractor
- 实现各类特征提取算法
- 使用FFT进行频域分析
- 支持音频分帧处理

### SampleLibrary
- 管理情感样本数据
- 维护特征统计信息
- 支持样本的导入导出

## 工作流程
1. 音频输入 -> 预处理
2. 特征提取 -> 特征向量
3. 特征匹配 -> 情感识别
4. 返回结果 -> Flutter端

## 性能优化
1. 预计算优化
   - FFT使用查找表
   - 窗函数预计算
   - 频率映射表缓存

2. 内存优化
   - 使用环形缓冲区
   - 原地FFT计算
   - 共享内存池

3. 并行处理
   - 特征提取并行化
   - 样本匹配并发计算
   - 统计更新异步处理

## 待优化项
- [ ] 实时处理性能优化
- [ ] 样本库扩充
- [ ] 特征权重动态调整
- [ ] 降噪算法改进
- [ ] 代码结构优化
  - [x] 统一数据结构定义
  - [x] 重构样本库实现
  - [ ] 提取公共工具函数
  - [ ] 优化错误处理
